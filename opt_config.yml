#Valid options: ['tree_parzen_estimators', 'random_search']. Mandatory field.
optimization_type: 'tree_parzen_estimators'
#number of initial random evaluations in tree_parzen_estimators mode. Not mandatory, default = 20
n_startup_jobs: 20
#seed. Not mandatory, default = None
random_state: [288]
#ctlearn_config file name. Mandatory. There must be a ctlearn config file in the working folder.
ctlearn_config: 'myconfig.yml'
#maximum number of model evaluations. Mandatory
num_max_evals: 40
#Resume optimization run. Valid options: True, False. If True, 'trials.pkl' will be loaded. Mandatory
reload_trials: False
#Valid options: True, False, if True, 'checking_file.csv' will be loaded. Mandatory
reload_checking_file: False
#Valid options: True, False. If false the CTLearn model will only be trained. Mandatory
predict: False
#set user defined metric to be computed on the validation set. Not mandatory, default = None
#expression has access to ['auc', 'acc', 'acc_gamma', 'acc_proton', 'loss'] (from validation set)
user_defined_metric_val:
  label: 'user_defined_val'
  expression: '(auc + accuracy_gamma)*0.5'
#set user defined metric to be computed on the prediction set, predict must be set to True. Not mandatory, default = None.
#expression has access to ['auc', 'accuracy', 'bacc', 'f1', 'prec', 'rec', 'log_loss'] (from prediction set)
#besides, expression has access to [labels, gamma_classifier_values, predicted_class] and sklearn.metrics
user_defined_metric_pred:
  label: 'user_defined_pred'
  expression: '(auc + f1 + sklearn.metrics.balanced_accuracy_score(labels, predicted_class))*0.5'
#set validation set metrics to log to the checking_file. Not mandatory, default = [].
#It's required to log at least the metric that is being optimized. _val will be appended to each metric logged
#valid options : ['auc', 'acc', 'acc_gamma', 'acc_proton', 'loss', 'user_defined_metric_val (label)']
metrics_val_to_log: ['auc', 'acc', 'acc_gamma', 'acc_proton', 'loss']
#set prediction set metrics to log to the checking_file. Not mandatory, default = [].
#It's required to log at least the metric that is being optimized. _pred will be appended to each metric logged
#valid options : ['auc', 'acc', 'bacc', 'f1', 'prec', 'rec', 'log_loss', 'user_defined_metric_pred (label)']
metrics_pred_to_log: ['auc', 'acc', 'bacc', 'f1', 'prec', 'rec', 'log_loss']
#valid options: ['prediction', 'validation']. If 'prediction', predict must be True. Mandatory.
data_set_to_optimize : 'validation'
#it has to be one metric belonging to metrics_val_to_log or metrics_pred_to_log:
metric_to_optimize : 'auc'

#Basic config for ctlearn config file. All fields, except prediction_file_list, are mandatory.
Basic_config:
  num_training_steps_per_validation: 2500
  num_validations: 15
  #options: ['array', 'single_tel']
  example_type: 'single_tel'
  #options:['cnn_rnn', 'single_tel']
  model: single_tel
  sorting: null
  min_num_tels: 1
  selected_tel_types: ['MST:NectarCam']
  training_file_list: 'data_train.txt'
  #Required if predict = True
  prediction_file_list: 'data_predict.txt'
  batch_size : 64
  model_directory: '/home/jredondo/ctlearn/ctlearn/default_models'
  validation_split: 0.1

#The choice of the hyperparameters' labels is left to the user , but they must
#be the same for all the following subsections
Hyperparameters:
  
  #list of the hyperparameters' labels to log to the checking_file. At least of label is mandatory
  Hyperparameters_to_log: [number_of_layers, layer1_filters,layer2_filters,layer3_filters,
                    layer4_filters,layer1_kernel, layer2_kernel, layer3_kernel, layer4_kernel]

# Dictionary containing (hyperparameter label : list containing hyperparameter CTLearn configuration)
# Must be detailed the configuration of each hyperparameter label used in  Fixed_hyperparameters,
# Dependent_hyperparameters and Hyperparameters_to_optimize subsections. Mandatory
  Config:
    pool_size: ['Model', 'Model Parameters', 'basic', 'conv_block','max_pool','size']
    pool_strides: ['Model', 'Model Parameters', 'basic', 'conv_block','max_pool','strides']
    optimizer_type: ['Training', 'Hyperparameters', 'optimizer']
    base_learning_rate: ['Training', 'Hyperparameters', 'base_learning_rate']
    adam_epsilon: ['Training', 'Hyperparameters', 'adam_epsilon']
    cnn_rnn_dropout: ['Model', 'Model Parameters', 'cnn_rnn', 'dropout_rate']
    layer2_filters: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 1, 'filters']
    layer3_filters: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 2, 'filters']
    layer4_filters: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 3, 'filters']
    layer1_filters: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 0, 'filters']
    layer1_kernel: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 0, 'kernel_size']
    layer2_kernel: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 1, 'kernel_size']
    layer3_kernel: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 2, 'kernel_size']
    layer4_kernel: ['Model', 'Model Parameters', 'basic', 'conv_block', 'layers', 3, 'kernel_size']

# Dictionary containing (hyperparameter label : value) pairs for each fixed hyperparameter.
# Not mandatory, default: None
  Fixed_hyperparameters:
    pool_size: 2
    pool_strides: 2
    optimizer_type: 'Adam'
    base_learning_rate: 5.0e-05
    adam_epsilon: 1.0e-08
    cnn_rnn_dropout: 0.5

# Dictionary containing (hyperparameter label : expression to evaluate) pairs for each dependent
# hyperparameter. Expression has access to all (hyperparameter label: value) pairs of the
# hyperparameters to optimize. Not mandatory, default: None
  Dependent_hyperparameters:

    layer2_filters: '2 * layer1_filters'
    layer3_filters: '4 * layer1_filters'
    layer4_filters: '8 * layer1_filters'

# Mandatory
# Examples are provided
  Hyperparameters_to_optimize:
# Type: hyperparameter distribution (q means integer)
# options: ['uniform', 'quniform', 'loguniform', 'qloguniform', 'normal',
# 'qnormal', 'lognormal', 'qlognormal', 'choice', 'conditional']

# range: range of values that the hyperparameter can take

# step: only for q-types (integer types), steps between the values that the hyperparameter can take

    base_learning_rate:
      type: loguniform
      range: [-5, 0]
    layer1_filters:
      type: 'quniform'
      range: [16, 64]
      step: 1
    layer1_kernel:
      type: 'quniform'
      range: [2, 10]
      step: 1
    layer2_kernel:
      type: 'quniform'
      range: [2, 10]
      step: 1
    layer3_kernel:
      type: 'quniform'
      range: [2, 10]
      step: 1
    layer4_kernel:
      type: 'quniform'
      range: [2, 10]
      step: 1
    optimizer_type:
     type: 'choice'
     range: ['Adadelta', 'Adam', 'RMSProp', 'SGD']
    cnn_rnn_dropout:
     type: 'uniform'
     range: [0,1]

    #example of conditional hyperparameter syntax
    number_of_layers:
     type: 'conditional'
     range:
        - value: 1
          cond_params:
            layer1_kernel:
              type: 'quniform'
              range: [2, 10]
              step: 1
            layer1_filters:
              type: 'quniform'
              range: [16, 64]
              step: 1
        - value: 2
          cond_params:
            layer1_kernel:
              type: 'quniform'
              range: [2, 10]
              step: 1
            layer1_filters:
              type: 'quniform'
              range: [16, 64]
              step: 1
            layer2_kernel:
              type: 'quniform'
              range: [2, 10]
              step: 1
            layer2_filters:
              type: 'quniform'
              range: [16, 128]
              step: 1
