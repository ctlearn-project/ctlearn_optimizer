#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import yaml
import shutil
import csv
import pickle
import ctlearn_optimizer.common as common
import logging
import numpy as np
from hyperopt import hp, STATUS_OK
from hyperopt.pyll.base import scope
from timeit import default_timer as timer
from time import sleep


def modify_optimizable_params(self, hyperparams):
    """Function that updates ctlearn config file with values of the new hyperparameters each iteration

    Args:
        self
        hyperparams: flat or nested dictionary containing hyperparameters to optimize generated by hyperopt fmin

    Returns:
        flat dictionary containing  dependent hyperparameters and hyperparameters to optimize
    """
    iteration = self.iteration

    #flatten optimizable hyperparameters dict if required
    def aux_flat(hyperparams):
        flat_hyperparams = {}
        for key, item in hyperparams.items():
            if type(item) is not dict:
                flat_hyperparams.update({key: item})
            else:
                flat_hyperparams.update(aux_flat(item))
        return flat_hyperparams

    hyperparams = aux_flat(hyperparams)

    #correct hyperparameters_to_optimize keys (hyperopt space creator doesn't
    #support repeated labels, so a ! character is appended to each repeated label)
    corrected_hyperparams = {}
    for key in hyperparams:
     if key.endswith('!'):
        dummy_key = key
        while dummy_key.endswith('!'):
            dummy_key = dummy_key[:-1]
        corrected_hyperparams.update({dummy_key: hyperparams[key]})
     else:
        corrected_hyperparams.update({key: hyperparams[key]})

    hyperparams = corrected_hyperparams

    #add dependent hyperparameters to the hyperparameters dict
    hyperparameters_config = self.opt_config['Hyperparameters']
    dependent_hyperparameters =  hyperparameters_config.get('Dependent_hyperparameters', None)
    if dependent_hyperparameters is not None:
        for param, expression in dependent_hyperparameters.items():
            hyperparams.update({param: eval(expression, hyperparams)})

    # update myconfig with the values in hyperparameters dict
    common.auxiliar_modify_params(self, hyperparams)

    with open(self.ctlearn_config, 'r') as config:
        myconfig = yaml.load(config)

    #set model and prediction_file_path
    myconfig['Logging']['model_directory'] = './run' + str(iteration)
    myconfig['Prediction']['prediction_file_path'] = \
    './run' + str(iteration) + '/predictions_run{}.csv'.format(iteration)

    with open(self.ctlearn_config, 'w') as config:
        yaml.dump(myconfig, config)

    return hyperparams

def hyperopt_space(self):
    """Function that creates hyperopt style hyperparameters space

    Args:
        self

    Returns:
        hyperopt style hyperparameters space to be fed into hyperopt fmin
    """

    def aux_hyperopt(key, typee, rangee, keys_list, step = None,):
        dict_type = {'uniform': hp.uniform,
                     'quniform': hp.quniform,
                     'loguniform': hp.loguniform,
                     'qloguniform': hp.qloguniform,
                     'normal': hp.normal,
                     'qnormal': hp.qnormal,
                     'lognormal': hp.lognormal,
                     'qlognormal': hp.qlognormal,
                     'choice': hp.choice,
                     'conditional': hp.choice}

        if typee in ('uniform', 'quniform', 'normal', 'qnormal'):
            if typee in ('uniform', 'normal'):
                element = {key: dict_type[typee](key, rangee[0], rangee[1])}
            else:
                element = {key: scope.int(dict_type[typee](key, rangee[0],
                           rangee[1], step))}

        elif typee in ('loguniform', 'qloguniform', 'lognormal', 'qlognormal'):
            if typee in ('loguniform', 'lognormal'):
                element = {key: dict_type[typee](key, np.log(rangee[0]),
                           np.log(rangee[1]))}
            else:
                element = {key: scope.int(dict_type[typee](key, np.log(rangee[0]),
                           np.log(rangee[1]), step))}

        elif typee in ('choice'):
            element = {key: dict_type[typee](key, [item for item in rangee])}

        #type is conditional
        else:
            stream_list = []
            for item in rangee:
                stream_dict = {}
                stream_dict.update({key:item['value']})

                for key_item, item in item['cond_params'].items():
                    #append a ! character to repeated keys
                    while key_item in keys_list:
                        key_item =  key_item + '!'
                    keys_list.append(key_item)

                    if 'step' in item:
                        aux = aux_hyperopt(key_item, item['type'], item['range'],
                                           keys_list, item['step'])
                        stream_dict.update(aux[0])
                        keys_list = aux[1]
                    else:
                        aux = aux_hyperopt(key_item, item['type'], item['range'],
                                           keys_list)
                        stream_dict.update(aux[0])
                        keys_list = aux[1]
                stream_list.append(stream_dict)
            element = {key: dict_type[typee](key, stream_list)}

        return element, keys_list

    #params = self.opt_config['Hyperparameters']['Hyperparameters_to_optimize']
    params = self.opt_config['Hyperparameters']['Hyperparameters_to_optimize']
    if params is None:
        raise KeyError('Hyperparameters_to_optimize is empty')
    space = {}
    keys_list = []
    for key, item in params.items():
        if 'step' in item:
            aux = aux_hyperopt(key, item['type'], item['range'], keys_list, item['step'])
            space.update(aux[0])
            keys_list = aux[1]
        else:
            aux = aux_hyperopt(key, item['type'], item['range'], keys_list)
            space.update(aux[0])
            keys_list = aux[1]
    return space

def objective(self, hyperparams):
    """Objective function for hyperopt input - output workflow

    Args:
        self
        hyperparams: set of hyperparameters to evaluate provided by hyperopt fmin

    Returns:
        metric to minimize by hyperopt fmin
    """

    self.iteration += 1
    self.counter += 1

    logging.info('Iteration: {0}' .format(self.counter))
    logging.info('Global iteration: {0}' .format(self.iteration))

    # update hyperparameters
    hyperparams_dict = modify_optimizable_params(self, hyperparams)

    start = timer()
    logging.info('Training')

    #train ctlearn network
    #this tries to solve a problem with the loading of the training data
    dummy = 1
    for x in range(0,9):
        #try to train the model
        try:
            common.train(self)
            dummy = None
        #log the error and remove the model directory created
        except Exception as str_error:
            logging.info('An error has occurred: {0}'.format(str_error))
            run_folder = './run' + str(self.iteration)
            shutil.rmtree(run_folder, ignore_errors=True)
            pass
        if dummy:
            sleep(10)
        else:
            break

    logging.info('Training ended')
    run_time = timer() - start

    # get validation set metrics
    metrics_val = common.get_val_metrics(self)
    metrics_pred = {}

    # predict if required
    if self.opt_config['predict']:
        logging.info('Predicting')
        common.predict(self)
        logging.info('Prediction ended')
        metrics_pred = common.get_pred_metrics(self)

    # set loss depending on metric and data set to optimize
    if self.opt_config['data_set_to_optimize'] == 'validation':
        metric = self.opt_config['metric_to_optimize'] + '_val'
        loss = 1 - metrics_val[metric]
        logging.info('{0}: {1}'.format(metric, metrics_val[metric]))

    elif self.opt_config['data_set_to_optimize'] == 'prediction':
        metric = self.opt_config['metric_to_optimize']+ '_pred'
        loss = 1 - metrics_pred[metric]
        logging.info('{0}: {1}'.format(metric, metrics_pred[metric]))


    # write hyperparameters and metrics in the checking_file
    with open('./checking_file.csv', 'a') as file:
        writer = csv.writer(file)

        row_hyperparams = []
        for element in self.opt_config['Hyperparameters']['Hyperparameters_to_log']:
            if element in hyperparams_dict:
                row_hyperparams.append(hyperparams_dict[element])
            else:
                row_hyperparams.append(0)

        row = [loss, self.iteration] + row_hyperparams + list(metrics_val.values()) + \
                list(metrics_pred.values()) + [run_time]
        writer.writerow(row)

    # save checking_trials file for resuming training if it has been interrupted
    pickle.dump(self.trials, open("checking_trials.pkl", "wb"))

    return {'loss': loss,'status': STATUS_OK}
